{
  "name": "llama-vscode",
  "displayName": "llama-vscode",
  "description": "Local LLM-assisted text completion using llama.cpp",
  "version": "0.0.8",
  "publisher": "ggml-org",
  "repository": "https://github.com/ggml-org/llama.vscode",
  "engines": {
    "vscode": "^1.70.0"
  },
  "icon": "llama.png",
  "activationEvents": [
    "onLanguage:plaintext",
    "onLanguage:javascript",
    "onLanguage:typescript",
    "onCommand.acceptFirstLine"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "languages": [
      {
        "id": "plaintext",
        "aliases": [
          "Plain Text"
        ],
        "extensions": [
          ".txt"
        ]
      }
    ],
    "commands": [
      {
        "command": "extension.triggerInlineCompletion",
        "title": "Trigger Inline Completion"
      },
      {
        "command": "extension.triggerNoCacheCompletion",
        "title": "Trigger No Cache Completion"
      },
      {
        "command": "extension.copyIntercept",
        "title": "Copy Intercept"
      },
      {
        "command": "extension.cutIntercept",
        "title": "Cut Intercept"
      },
      {
        "command": "extension.acceptFirstLine",
        "title": "Accept First Line"
      },
      {
        "command": "extension.acceptFirstWord",
        "title": "Accept First Word"
      },
      {
        "command": "extension.copyChunks",
        "title": "Copy Chunks"
      },
      {
        "command": "extension.showMenu",
        "title": "Show Menu"
      }
    ],
    "keybindings": [
      {
        "key": "tab",
        "command": "editor.action.inlineSuggest.commit",
        "when": "inlineSuggestionVisible"
      },
      {
        "command": "extension.triggerInlineCompletion",
        "key": "ctrl+l",
        "when": "editorTextFocus"
      },
      {
        "command": "extension.triggerNoCacheCompletion",
        "key": "ctrl+shift+l",
        "when": "editorTextFocus"
      },
      {
        "command": "extension.copyChunks",
        "key": "ctrl+shift+,",
        "when": "true"
      },
      {
        "command": "extension.copyIntercept",
        "key": "ctrl+c",
        "when": "editorTextFocus"
      },
      {
        "command": "extension.cutIntercept",
        "key": "ctrl+x",
        "when": "editorTextFocus"
      },
      {
        "command": "extension.acceptFirstLine",
        "key": "shift+tab",
        "when": "editorTextFocus && inlineSuggestionVisible"
      },
      {
        "command": "extension.acceptFirstWord",
        "key": "ctrl+right",
        "when": "editorTextFocus && inlineSuggestionVisible"
      },
      {
        "command": "extension.showMenu",
        "key": "ctrl+shift+m",
        "when": "true"
      }
    ],
    "configuration": {
      "type": "object",
      "title": "llama.vscode Configuration",
      "properties": {
        "llama-vscode.launch_cmd": {
          "type": "string",
          "default": "",
          "description": "Shell command executed from menu"
        },
        "llama-vscode.endpoint": {
          "type": "string",
          "default": "http://127.0.0.1:8012",
          "description": "The URL to be used by the extension."
        },
        "llama-vscode.auto": {
          "type": "boolean",
          "default": true,
          "description": "If code completion should be trggered automatically (true) or only by pressing Ctrl+l."
        },
        "llama-vscode.api_key": {
          "type": "string",
          "default": "",
          "description": "llama.cpp server api key or OpenAI endpoint API key (optional)"
        },
        "llama-vscode.n_prefix": {
          "type": "number",
          "default": 256,
          "description": "number of lines before the cursor location to include in the local prefix"
        },
        "llama-vscode.n_suffix": {
          "type": "number",
          "default": 64,
          "description": "number of lines after  the cursor location to include in the local suffix"
        },
        "llama-vscode.n_predict": {
          "type": "number",
          "default": 128,
          "description": "max number of tokens to predict"
        },
        "llama-vscode.t_max_prompt_ms": {
          "type": "number",
          "default": 500,
          "description": "max alloted time for the prompt processing (TODO: not yet supported)"
        },
        "llama-vscode.t_max_predict_ms": {
          "type": "number",
          "default": 500,
          "description": "max alloted time for the prediction"
        },
        "llama-vscode.show_info": {
          "type": "boolean",
          "default": true,
          "description": "show extra info about the inference (false - disabled, true - show extra info in status line)"
        },
        "llama-vscode.max_line_suffix": {
          "type": "number",
          "default": 8,
          "description": "do not auto-trigger FIM completion if there are more than this number of characters to the right of the cursor"
        },
        "llama-vscode.max_cache_keys": {
          "type": "number",
          "default": 250,
          "description": "max number of cached completions to keep in result_cache"
        },
        "llama-vscode.ring_n_chunks": {
          "type": "number",
          "default": 16,
          "description": "max number of chunks to pass as extra context to the server (0 to disable)"
        },
        "llama-vscode.ring_chunk_size": {
          "type": "number",
          "default": 64,
          "description": "max size of the chunks (in number of lines). Note: adjust these numbers so that you don't overrun your context at ring_n_chunks = 64 and ring_chunk_size = 64 you need ~32k context"
        },
        "llama-vscode.ring_scope": {
          "type": "number",
          "default": 1024,
          "description": "the range around the cursor position (in number of lines) for gathering chunks after FIM"
        },
        "llama-vscode.ring_update_ms": {
          "type": "number",
          "default": 1000,
          "description": "how often to process queued chunks in normal mode"
        },
        "llama-vscode.language": {
          "type": "string",
          "default": "en",
          "description": "language: bg - Bulgarian (Български), cn - Chinese (中文), en - English, fr - French (Français), de - German (Deutsch), ru - Russian (Русский), es - Spanish (Español)"
        },
        "llama-vscode.enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable/disable completions"
        },
        "llama-vscode.languageSettings": {
          "type": "object",
          "default": {
            "*": true
          },
          "additionalProperties": {
            "type": "boolean"
          },
          "description": "Enable/disable suggestions for specific languages"
        },
        "llama-vscode.use_openai_endpoint": {
          "type": "boolean",
          "default": false,
          "description": "[EXPERIMENTAL] Use OAI endpoint. Slow and poor quality - avoid using"
        },
        "llama-vscode.openai_client_model": {
          "type": "string",
          "default": "",
          "description": "The FIM friendly model supported by your OpenAI compatible endpoint to be used (e.g., Qwen2.5-Coder-14B-4-bit)"
        },
        "llama-vscode.openai_prompt_template": {
          "type": "string",
          "default": "<|fim_prefix|>{inputPrefix}{prompt}<|fim_suffix|>{inputSuffix}<|fim_middle|>",
          "description": "The prompt template to be used for the OpenAI compatible endpoint."
        }
      }
    },
		"viewsContainers": {
			"activitybar": [
				{
					"id": "llama-vscode-ActivityBar",
					"title": "llama.cpp",
					"icon": "icon.svg"
				}
			]
		},
		"views": {
			"llama-vscode-ActivityBar": [
				{
					"type": "webview",
					"id": "llama-vscode.SidePanel",
					"name": ""
				}
			]
		}
  },
  "scripts": {
    "watch": "tsc -watch -p ./",
    "build:webview": "webpack --mode production",
    "watch:webview": "webpack --mode development --watch"
  },
  "dependencies": {
    "@vscode/webview-ui-toolkit": "^1.4.0",
    "axios": "^1.1.2",
    "openai": "^4.86.1",
    "react": "^17.0.2",
    "react-dom": "^17.0.2",
    "react-use": "^17.6.0"
  },
  "devDependencies": {
    "@types/jest": "^29.5.14",
    "@types/node": "^18.0.0",
    "@types/react": "^17.0.53",
    "@types/react-dom": "^17.0.19",
    "@types/vscode": "^1.70.0",
    "@types/vscode-webview": "^1.57.5",
    "css-loader": "^6.8.1",
    "style-loader": "^3.3.3",
    "ts-loader": "^9.5.1",
    "typescript": "^4.8.0",
    "webpack": "^5.0.0",
    "webpack-cli": "^4.0.0"
  }
}
